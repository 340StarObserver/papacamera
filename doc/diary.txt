日报 -- 吕炀


--------------------------------------------------


2016-07-11

1， python开发规范文档  

2， 摸索图片识别的架构( 数据流向 & 哪些进程 )  


--------------------------------------------------


2016-07-12

1， 学习kafka  

2， kafka处理图片消息的原型模块  
        使用 kafka-python 扩展  
        producer端 从本地读取一张200K的图片，转化为base64编码，发送给kafka(指定了该条消息的key)  
        consumer端 从kafka取出消息，打印出该条消息的(topic,partition,offset,key,value)，并把value通过base64解码，写入本地文件，生成一张本地图片  

3， 在master服务器上安装配置 redis及python的redis扩展  

4， 在master服务器上安装配置 kafka及python的kafka扩展  
        在关闭服务( 即执行kafka-server-stop.sh 和 zookeeper-server-stop.sh )时存在问题，提示"No kafka server to stop"  
        目前尚未找到解决办法，只有靠kill强行干掉，在我本地的ubuntu15.10的机子上无此问题，猜测可能是由于系统版本造成的问题。接收与取出消息的操作是正常的  


--------------------------------------------------


2016-07-13

1， 图片识别业务的架构设计文档  
        先阶段的架构设计  
        未来的架构设计  

2， 图像识别业务的webserver程序开发  
        使用python-flask框架开发  
        遇到问题，任何类型的消息，发送给kafka后，消费者进程都能收到  
        然而只要把生产者的代码放到flask里面去调用，则虽然也不会报错，但是消费者那边却始终没有任何动静，即使把kafka的消息发送模式设置为同步且最高确认模式，还是没有用。目前还没找到原因与解决方案  


--------------------------------------------------


2016-07-14

1， 解决了在flask中调用kafka-producer后consumer收不到消息的问题  
        具体的方案是这样的 :  
        1-1.    第一件事是要在producer发送消息后，sleep十毫秒左右  
        1-2.    如果在GET请求中，做第一件事就够了  
        1-3.    如果在POST请求中，第二件事是不能同时接收图片和非图片  
        解决方案也是比较怪异的，无法理解，先这样吧  

2， python-webserver程序中的flask程序开发  
        flask的框架程序，还缺一步是根据识别返回的图片id来从数据库查找具体的信息，具体查找哪些信息还未确定  

3， redis-cluster  
        在master服务器上安装配置redis小集群  
        redis集群的运维文档的撰写  


--------------------------------------------------


2016-07-15

1， 图片特征数据存储模块  
        在master,slave1,slave2主机上配置webHDFS  
        在master主机上安装pyhdfs  
        从hdfs中读取某张图片的特征数据    
        将某张图片的特征数据存储到hdfs  


--------------------------------------------------


2016-07-16

1， spark-streaming程序的框架结构  
        消费者进程的桩程序  
        待接入图像识别的函数  


--------------------------------------------------


2016-07-19

1， 解决了通过客户端传来的二进制图片数据流，来计算出特征数据  

2， 解决了图片的特征数据的序列化和反序列化  

3， 整理 map & reduce 的逻辑  


--------------------------------------------------


2016-07-20


1， 解决了一次性以HDFS为数据源构建大的RDD  

2， 解决了目前为止算法中使用的数据结构不能序列化传输的问题  

3. 重新定义了 map & reduce 的逻辑　


--------------------------------------------------


2016-07-21

1， 解决了闭包的问题  

2， 重写了消费者程序的形式，弃用了spark-streaming的方式  

3， 读取本地图片并把特征数据入库的管理脚本  

4. 重构代码-_-  


--------------------------------------------------


2016-07-22

1， 整个流程跑通，还缺几个桩函数的内部实现  

2， 服务器磁盘扩容  


--------------------------------------------------


2016-07-23

1， 三台服务器日志数据整理迁移  

2， 集成各模块并测试（可以跑通，但是很慢...）  


--------------------------------------------------


2016-07-26

1， 彻底解决flask中向kafka写入消息，结果消费者收不到消息的问题  

            假设客户端一次性发送了 : 一个文件（名为targetfile），两个数字(名为pos_x和pos_y)  
            flask服务端的解决方案是这样的 :  

            获取图片的二进制内容 :  
            flask.request.files['targetfile'].read()  

            获取两个数字参数 :  
            post_data=dict(flask.request.form)  
            pos_x=post_data['pos_x'][0]  
            pos_y=post_data['pos_y'][0]  
            // 此处不能用 flask.request.form['pos_x']  
            // 也不能够用 flask.request.form.get('pos_x')  
            // 也不能够用 flask.request.values.get('pox_x')  
            // 否则，kafka的消费者那端就会收不到消息  
            // 很诡异，但是目前的这个方案能够解决问题  

2， 理了一下用机器学习代替surf算法的思路  


--------------------------------------------------


2016-07-29

1， 彻底解决了spark运行时反复对RDD中的数据进行序列化和反序列化的问题  

            因发现算法中实际用的也是特征数据对象中的属性，所以计算图片的特征数据后就直接转换为列表和元组的嵌套  
            这样一来，在做map和reduce的时候，用不着序列化和反序列化了  

2， 优化了数据本地化  

            在启动spark的时候，就对图库中全部特征数据所构造出来的shared_rdd进行持久化  
            这样一来，之后处理客户端的请求时，就不用每次传输所有数据，虽然还是要传输部分数据，但是要传的东西少了很多  

3， 图片识别业务跑通，但存在问题 :  

            安卓（试了几台安卓）传来的图片，识别计算的时间在0.3~0.6秒之间
            （不算网络传输的时间以及轮询redis的间隔等待时间），识别率较高  
            
            IOS传来的图片，不仅计算慢（是安卓的十倍-_-），而且识别率还低...  

4， 图像特征入库优化  

5， 在yarn模式下跑spark，发现map-reduce函数中如果用了自己写的模块，则会报错找不到该模块  


--------------------------------------------------


2016-07-30

1， 图片识别出id后，再查数据库获取广告的详细信息  

2， 解决了 yarn-client 模式下的 no module named xxx 的问题  

            法一 :  
                把map-reduce函数中依赖的自定义模块，打包成egg，使用SparkContext对象把egg分发给workers  
                但是需要在map-reduce函数中，对于RDD中的每个元素的处理，都要import一次，开销巨大  

            法二 :  
                把map-reduce函数中依赖的自定义模块，全部放到spark程序的主文件里-_-  
                这个方法很违背模块化，但是没找到更好的解决方案前，先用这个法子吧...  

            # 但是 yarn-cluster 模式的运行，还在探索  


--------------------------------------------------


2016-07-31

1， 重构initkafka.py  

2， 图片识别业务的部署文档  


--------------------------------------------------


2016-08-01

1， 学习jmeter  

2， 辅助重构数据库，广告业务向mongodb迁移  


--------------------------------------------------


2016-08-02 ~ 2016-08-05

1， 广告信息数据的重构  

2， 测试客户端上传图片宽高，大小　与　识别时间，识别率　的关系  

3， 测试图库中样张宽高，大小　与　识别时间，识别率的关系  


--------------------------------------------------


2016-08-06

1， 测试新改动后的算法，记录所有误判的数据  


--------------------------------------------------


2016-08-10

1， 图片识别业务的数据收集  

        客户端上传的待识别图片，保存至OSS  
        识别的结果，批量地写至HDFS  


--------------------------------------------------


2016-08-12

1， 优化程序的内存管理  


--------------------------------------------------


2016-08-14

1， 把日志收集程序转移到spark消费者程序中  

2， 修改程序，优化master结点的内存消耗  
